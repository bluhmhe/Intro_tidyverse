---
title: "Introduction to tidyverse - A new grammar"
author: "Francesco Maria Sabatini"
date: "3/22/2020"
output: html_document
---
  
**Timestamp:** `r date()`  
**Drafted:** Francesco Maria Sabatini  
**Revised:**  
**version:** 1.0

`tidyverse` is a a collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures. Working in the `tidyverse` requires a basic understanding of `dplyr`, 
a package which provides a set of tools for efficiently manipulating datasets in R.  
What I personally love is that `dplyr` is **synthetic, fast and easy to read**. It allows to write code which is easy to explain, revise and mantain. Knowing that whather analysis we do, we will probably have to adjust and re-run it over and over, using `dplyr`'s grammar now is the best present we can give to our *future selves*, since it will help us save a *lot* of time later.  
\newline 

The overarching goals of this tutorial is to fall in love with `dplyr` and to see some cute wild cats. The specific goals are:  
- Understand the logic of `dplyr` and the power of piping `%>%`  
- Explore the key verbs of `dplyr`'s grammar  
- Simulate a `dplyr` based workflow  
\newline

You will learn how to use the key verbs of `dplyr`, including `select`, `filter`, `mutate`, `summarize`, `rename`, as well as their generalized `x_at` and `x_all` versions. We'll also touch on the `join` family of functions.  

\newline

We will first create a simulated dataframe using data from `GBIF` and environmental predictors from some global datasets.

```{r results="hide", message=F, warning=F}
library(tidyverse)
library(downloader)
library(rgbif)

## Markdown packages
library(knitr)
library(kableExtra)
knitr::opts_chunk$set(echo = TRUE)
## Spatial packages
#install.packages(c("rgdal", "sp", "sf", "rgeos", "raster", "rnaturalearth"))
library(rgdal)
library(sp)
library(sf)
library(rgeos)
library(raster)
library(rnaturalearth)
#library(rworldmap)


#library(elevatr)

#save temporary files
write("TMPDIR = _tmp", file=file.path(Sys.getenv('TMPDIR'), '.Renviron'))
write("R_USER = _tmp", file=file.path(Sys.getenv('R_USER'), '.Renviron'))
rasterOptions(tmpdir="_tmp")
```

### Import species data from `GBIF`
As a toy dataset, we will compare the climatic niche of the five cutest wild cats out there. The selection follows the authoritative source [www.backyardcatenclosures.com.au](https://www.backyardcatenclosures.com.au/blogs/cute-cat/5-cute-wild-cat-breeds).  
\newline


SPOILER:  
The winner is...  
<center>
  ![](`r "https://upload.wikimedia.org/wikipedia/commons/b/bd/Margay_in_Costa_Rica.jpg"`)  
</center>
  
*the Margay!* (Source: [Wikipedia](https://en.wikipedia.org/wiki/Margay))  
\newline 

\newline  

Define our set of species and download occurrences from `GBIF`

```{r}
myspecies <- c("Otocolobus manul", #Palla's cat
               "Caracal caracal", #Caracal
               "Felis margarita", #Sand cat
               "Prionailurus rubiginosus", #Rusty spotted cat
               "Leopardus wiedii" #Margay
               )
shortnames <- c("Pallas", "Caracal", "Sand", "Rusty", "Margay")
get.speciesKey <- function(x){name_backbone(x)$speciesKey} #get GBIF species key
key <- unlist(lapply(myspecies, get.speciesKey))
get.100occurrences <- function(x){occ_search(taxonKey=x, return="data", limit=100)}
#dat <- occ_search(taxonKey=key, return='data', limit=300)
dat <- lapply(key, get.100occurrences)
```


We produce a list of 5 elements, each with up to 100 occurrences for a cat. Let's take a look at the output:

```{r, echo=F}
knitr::kable(dat[[1]][1:10,], 
             caption="Five cutest wild cat species from GBIF (first cat, first 10 rows shown)", digits = 3) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), 
                full_width = F, position = "center")
```

It's pretty horrible, and there's a lot of information we probably do not need. 
First, notice that each element of the list is a `tibble`, which is the `dplyr` equivalent of a `data.frame`. It has some cool tweaks (try to visualize a tibble in your console) compared to a data.frame. You  should be aware, though, that some functions designed for data.frames may not work with tibbles. Try converting back and forth from data.frame to tbl with the commands `as.data.frame` and `as.tbl`  
\newline

### Clean data
Let's see how `dplyr` can help us to clean up our data into something we can work with:   
1) bind all rows into a single data.frame  
2) select the columns we need (species, country, coordinates)  
3) filter out all observation without spatial coordinates  
4) rename columns to make our life easier later  
\newline

We'll do this through piping  

The command pipe ` %>%` (shortcut in RStudio: `Ctrl + Shift + m`) allows to use the output of a previous function as the input of the following. This means we can avoid a *lot* redundancy in our code.  
\newline

Let's compare the code in `base` vs. the code in `dplyr`.

```{r}
#base
#Since each element of the list has a different number of columns, I cannot simply bind them by rows, but I first need to subset them to the same format.
dat_clean <- NULL
for(i in 1:5){
  dat_clean <- rbind(dat_clean, dat[[i]][,which(colnames(dat[[i]]) %in%  
                                                  c("species", "country", "decimalLongitude", "decimalLatitude"))])
}
dat_clean <- dat_clean[which(!is.na(dat_clean$decimalLatitude) & !is.na(dat_clean$decimalLongitude)),]
colnames(dat_clean)[2:3] <- c("Lat", "Lon")
dat_clean <- dat_clean[,c(1,4,3,2)] #reorder columns
head(dat_clean)
```

```{r}
#dplyr
dat_clean <- dat %>% 
  bind_rows() %>% 
  dplyr::select(species, country, decimalLongitude, decimalLatitude) %>% 
  filter(!is.na(decimalLongitude) & !is.na(decimalLatitude)) %>% 
  rename(Lon=decimalLongitude, Lat=decimalLatitude)
head(dat_clean)
```
Shorter, cleaner, easier.  
Congratulations. You did your first piping. A few features worth noting:  
- In the first row, we assign the output to the object `dat_clean` and select `dat` as initial input of our chain of commands. The object `dat` will be fed into the first function (`bind_rows`). The output from the first function will be fed as first argument in the second function (`select`) and so on  
- `bind_rows` is a pretty powerful alternative to rbind, which has the desirable properties of binding rows only when these have the same column name (!), which avoids us having to select columns separately for each element of the `dat` list in a loop    
- For the function `select` I specified the package because there's a conflict with the `raster::select` function. When doing spatial analysis, it's more robust to consistently specifiy the package when conflicts may exist  
- `dplyr` *DOES NOT* need quoting column names (but doesn't mind if you quote either). It may be confusing at first, but it allows to work quicker, and avoids filling up your code with distracting elements.  
\newline

It can be tedious to explicitly specify all the column names to select. `dplyr` is the best friend of lazy people, and provide a quicker way for selection multiple columns.
```{r}
dat2 <- dat %>% 
  bind_rows() %>% 
  dplyr::select(kingdom:species, year:day, country, decimalLongitude, decimalLatitude, everything())
```
See how we used the function `everything` to select all the remaining columns (which can be really useful when we are simply changing the order of our columns)




### Create a map of data
We are now ready to plot these points on a map. 
The map of the worls here derives from the package `rnaturalearth`. Plotting is done using `ggplot` another important member of the `tidyverse`. Spatial data are handled using the `sf` library. All very cool stuff that we don't discuss here.
```{r, message=F, warning=F, eval=F}
countries <- ne_countries(returnclass = "sf") %>% 
  st_geometry()

## basic graph of the world in Eckert projection
ggplot() +
  geom_sf(data = countries, fill = "grey90", col = NA, lwd = 0.3) +
  geom_point(data=dat_clean, aes(x=Lon, y=Lat, col=species)) +
  theme_bw() 
```
There's a point for the Sand cat which is clearly out of the species native range. We delete it.
```{r}
dat_clean <- dat_clean %>% 
  filter(!(species=="Felis margarita" & country=="United States of America"))
```

### Extract predictors from global datasets
Imagine we are interesting in calculating some metrics related to the environmental niche of the five cute cat species. Do do spatial operations, we need to transform our dataset into a `SpatialPointDataFrame`. 
```{r}
dat.shp <- SpatialPointsDataFrame(coords=dat_clean %>% 
                                    dplyr::select(Lon, Lat), 
                                  data=dat_clean %>% 
                                    dplyr::select(species, country), 
                                  proj4string = CRS("+init=epsg:4326")) #Lat long in WGS 84
                                  
```
We can then download Bioclimatic variables from [CHELSA](http://chelsa-climate.org/bioclim/)  
We focus on two only:  
\newline
  
Bio1 = Annual Mean Temperature  
Bio12 = Annual Precipitation  

\newline 

\newline
Download raster files:
```{r, message=F, warning=F, eval=F}
dir.create("Ancillary_data")
dir.create("Ancillary_data/CHELSA")
url.chelsa <- list()
ii <- stringr::str_pad(c(1,12), width=2, side="left", pad="0")
url.chelsa <- paste("https://envidatrepo.wsl.ch/uploads/chelsa/chelsa_V1/bioclim/integer/CHELSA_bio10_", ii, ".tif", sep="")
for(i in 1:2){
  download(url.chelsa[[i]],
           paste("Ancillary_Data/CHELSA/CHELSA_bio10_", ii[i], ".tif", sep=""), 
           mode = "wb")
}
```

Load CHELSA rasters, and intersect `dat.shp` with each of them 
```{r, warning=F, message=F}
bio01.raster <- raster("Ancillary_Data/CHELSA/CHELSA_bio10_01.tif")
bio12.raster <- raster("Ancillary_Data/CHELSA/CHELSA_bio10_12.tif")

bio01 <- raster::extract(bio01.raster, dat.shp) # Â°C * 10
bio12 <- raster::extract(bio12.raster, dat.shp) # mm
```
Bind columns and transform temperature data (They are multiplied by 10 to be stored as integers). 
```{r}
envdata <- dat_clean %>% 
  mutate(Temp=bio01) %>% 
  mutate(P=bio12) %>% 
  mutate(Temp=Temp/10)
```
The function `mutate` is a fundamental one. It allows creating and modifying a column, and can be used to do operations between columns.  
\newline

Now things get interesting. To calculate the climatic niche we may want to calculate some statistics for each predictor for species (min, max, mean). `dplyr` comes to our help with the function `group_by` (and it's opposite `ungroup`). Once you group a data.frame by a factor (or character!), all operations are applied on a group by group basis. Easy, quick, efficient. We can then use the function `summarize`.
```{r}
niche <- envdata %>% 
  group_by(species) %>% 
  summarize(n=n(), 
            min.T=min(Temp, na.rm=T),
            mean.T=mean(Temp, na.rm=T),
            max.T=max(Temp, na.rm=T),
            min.P=min(P, na.rm=T),
            mean.P=mean(P, na.rm=T),
            max.P=max(P, na.rm=T))
```
Checkout how we used the function `n()` to count the number of observations for each group!.  
\newline

How do our cute cats rank in terms of their resistance to maximum temperature? All we have to do is to `arrange` our rows in a descending order.
```{r}
niche %>% 
  arrange(desc(max.T))
```
To sort in ascending order, it's enough to do `arrange(niche, max.T)`.  
You, fine ecologists, may be unhappy of the unequal sample size in our data. How would the result change if we were using only one randomly selected observations for each species in each country?  
Easy-peasy.  
All we need to do is to group our data by both species AND country, and then we can take advantage of a bunch of useful commands which subset our dataset by selecting only a set of rows. Check `slice`, `sample_n`, `sample_frac`.
```{r}
envdata %>% 
  group_by(species, country) %>% 
  sample_n(1, replace=F) %>% 
  head()
```
Note that many `base` functions useful for checking the shape of your dataset work also when put in the pipe. Try for instance to add at the end of your pipe the commands `nrow`, `ncol`, `dim`, `class`, `str`, `head`, `summary`.  
\newline

Often, you have the need to delete duplicated rows in your dataset. Let's say we want to count the number of countries we have data for, separately for each cute cat. Our best friend is the command `distinct`
```{r}
ncountries <- envdata %>% 
  group_by(species) %>% 
  distinct(country) %>% 
  summarize(n=n())
```
!! watch out. By using `distinct` you effectively use (and retain) only the information in the column(s) you are using `distinct` on. If you want to retain the information in the other columns, try `distinct(country, .keep_all=T)`.  
\newline


Transforming all your scripts to `dplyr` grammar may be challenging at first. Sometimes you want to extract one column from a dataframe and use it as a vector. You can obviously run your pipe, and then subset the output using the `$` sign, as usual. A real `dplyr` feticist would never do it, though, but rather use `pull`.  
Let's say we want to extract the string of countries we have data for (altogehter, this time, not separately by species) 
```{r}
envdata %>% 
  distinct(country) %>% 
  pull(country)
```
Cool. This is it. Now you know the basics and you can start navigating on your own.

### Slighlty more advanced stuff
The power of `dplyr` is that you can really make your data management workflow more general, by writing your code more programmatically. We are only touching this argument here, but I want to introduce you to two cool families of functions.

*Joins*
Often, we need to join information based on two or more data.frames, based on a common field. `dplyr` has the whole family of join functions which we can use: `left_join`, `right_join`, `full_join`, `inner_join`. Here I just show one simple application.  
Let's say we want to standardize the Temperature values of each individual observation, by the maximum Temperature we calculated for each cute cat species. Basically, we need to join our  `envdata` object with our `niche` object, using `species` as key.
```{r}
envdata.st <- envdata %>% 
  left_join(niche %>% 
              dplyr::select(species, max.T), 
            by="species") %>% 
  mutate(Temp.st=Temp/max.T)
head(envdata.st)
```
Notice how we nested a pipe within a pipe!

Not everybody knows, you can join an object with itself using the point `.`. In `dplyr` grammar the point `.` sign symbolizes 'iteself' and it's use is widespread. In the next example we first calculate the maximum temperature, species by species, and then join these summarizes values to the `envdata` object

```{r}
envdata.st <- envdata %>%
  left_join(x=., 
            y={.} %>% 
              group_by(species) %>% 
              summarize(max.T=max(Temp, na.rm=T)), 
            by="species") %>% 
  mutate(Temp.st=Temp/max.T)
head(envdata.st)
```
Not convinced by the power? Let's see how to do the same in `base`
```{r}
#calculate max for each species
Tmax.sp <- tapply(envdata$Temp, envdata$species, "max", na.rm=T)
Tmax.sp <- data.frame(species=names(Tmax.sp), max.T=Tmax.sp)
index1 <- match(envdata$species, Tmax.sp$species)
envdata2 <- data.frame(envdata, max.T=Tmax.sp$max.T[index1])
envdata2$Temp.st <- envdata2$Temp/envdata2$max.T
head(envdata2)
```
Three versions for the same task. Which one is easier to read?  
\newline

*_at & _all* family  
All basic functions in `dplyr` have an `x_at` and an `x_all` version. This helps **enormously** to script in a more general and programmatical.  
Remember when we summarized temperature and precipitation to get min, mean and max? Actually, our code had some redundancy that a `dplyr` would never accept. Imagine we have to calculate summaries for all the 18 bioclim variables in Chelsa. Should we repeat the same lines 18 times?  
NO!!  
We can simply use the function `summarize_at`. The grammar is slighlty more complicated, but discloses a world of opportunities.
```{r}
niche <- envdata %>% 
  group_by(species) %>% 
  summarize_at(.vars=vars(Temp, P), 
               .funs=list(min=~min(., na.rm=T), 
                          mean=~mean(., na.rm=T), 
                          max=~max(., na.rm=T)))
niche
```
Awesome! Not only we summarized ove both variables, but we also got columns having the correct naming. HOW COOL IS THAT?  
Spend a minute looking at the syntax of `summarize_at`. Not exactly simple, with those point `.` and tilde `~` signs. Definitely worth learning, though.  
\newline

If it's not yet enough, let's look at another application of the `_at` family.  
Let's say we are doing an analysis on the summarized data, and decided to transform to log all the summarized variables referring to P in `niche`.

```{r}
niche.log <- niche %>% 
  mutate_at(.vars=vars(starts_with("P_")), 
            .funs=list(~log(.)))
niche.log
```
Notice that, not defining new names in the `.funs` argument, we are not overwriting the variables that we selected in the `.vars` argument. The function `starts_with` (and its companions `ends_with`, `contain`), are cool helper functions especially though for selecting columns (which means they can also be used when using the `select` function)















